{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd3480b1",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0a539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98ca7f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('C:/Users/abdou/Documents/Data_Science_Projects/AbdoulT_DSPortfolio/Credit Risk Modeling Projects/Credit Default Prediction Using Logistic Regression and XGBoost/data/cleaned_credit_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345ee2f9",
   "metadata": {},
   "source": [
    "# Features Engineered\n",
    "pay_avg: Avg. of past due payment statuses\n",
    "\n",
    "bill_avg: Avg. of past 6 bill amounts\n",
    "\n",
    "pay_amt_avg: Avg. of past 6 payments made\n",
    "\n",
    "credit_utilization: Ratio of the average amount paid to the average bill amount, showing how much of their credit card bill a client typically pays off. \n",
    "It is an important indicator of credit risk and financial responsibility.\n",
    "\n",
    "utilization: Proxy for credit risk behavior. It measures what proportion of the available credit limit was used by the client in the latest month.\n",
    "\n",
    "Standard scaling and SMOTE applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58248f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Variable\n",
    "target = 'default'\n",
    "\n",
    "df['pay_avg'] = df[['pay_1', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6']].mean(axis=1)\n",
    "df['bill_avg'] = df[['bill_amt1', 'bill_amt2', 'bill_amt3', 'bill_amt4', 'bill_amt5', 'bill_amt6']].mean(axis=1)\n",
    "df['pay_amt_avg'] = df[['pay_amt1', 'pay_amt2', 'pay_amt3', 'pay_amt4', 'pay_amt5', 'pay_amt6']].mean(axis=1)\n",
    "\n",
    "# Cedit Utilization\n",
    "df['credit_utilization'] = df['pay_amt_avg'] / df['bill_avg']\n",
    "\n",
    "# Credit Utilization Ratio for most recent month\n",
    "df['utilization'] = df['bill_amt1'] / (df['limit_bal'] + 1)\n",
    "\n",
    "# Drop ID column and irrelevant features\n",
    "df.drop(columns=['id'], errors='ignore', inplace=True)\n",
    "\n",
    "# Drop EDA columns\n",
    "eda_columns = ['education_level', 'relationship_status', 'age_group', 'credit_card_limit']\n",
    "df.drop(columns=eda_columns, errors='ignore', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ce26c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   limit_bal  sex  education  marriage  age  pay_1  pay_2  pay_3  pay_4  \\\n",
      "0    20000.0    2          2         1   24      2      2     -1     -1   \n",
      "1   120000.0    2          2         2   26     -1      2      0      0   \n",
      "2    90000.0    2          2         2   34      0      0      0      0   \n",
      "3    50000.0    2          2         1   37      0      0      0      0   \n",
      "4    50000.0    1          2         1   57     -1      0     -1      0   \n",
      "\n",
      "   pay_5  ...  pay_amt3  pay_amt4  pay_amt5  pay_amt6  default   pay_avg  \\\n",
      "0     -2  ...       0.0       0.0       0.0       0.0        1 -0.333333   \n",
      "1      0  ...    1000.0    1000.0       0.0    2000.0        1  0.500000   \n",
      "2      0  ...    1000.0    1000.0    1000.0    5000.0        0  0.000000   \n",
      "3      0  ...    1200.0    1100.0    1069.0    1000.0        0  0.000000   \n",
      "4      0  ...   10000.0    9000.0     689.0     679.0        0 -0.333333   \n",
      "\n",
      "       bill_avg  pay_amt_avg  credit_utilization  utilization  \n",
      "0   1284.000000   114.833333            0.089434     0.195640  \n",
      "1   2846.166667   833.333333            0.292791     0.022350  \n",
      "2  16942.166667  1836.333333            0.108388     0.324874  \n",
      "3  38555.666667  1398.000000            0.036259     0.939781  \n",
      "4  18223.166667  9841.500000            0.540054     0.172337  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "Training set shape: (37382, 28), (37382,)\n",
      "Testing set shape: (9346, 28), (9346,)\n"
     ]
    }
   ],
   "source": [
    "# Define Features and Target\n",
    "x = df.drop(columns=[target])\n",
    "y = df[target] \n",
    "\n",
    "# Handle infinite values and NaNs before scaling\n",
    "x = x.replace([np.inf, -np.inf], np.nan)\n",
    "x = x.fillna(x.mean())\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "x_scaled = pd.DataFrame(scaler.fit_transform(x), columns=x.columns)\n",
    "\n",
    "# Apply SMOTE for handling class imbalance\n",
    "smote = SMOTE(random_state=85)\n",
    "X_resampled, y_resampled = smote.fit_resample(x_scaled, y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=85, stratify=y_resampled)\n",
    "\n",
    "# Save the processed data\n",
    "X_train.to_csv('C:/Users/abdou/Documents/Data_Science_Projects/AbdoulT_DSPortfolio/Credit Risk Modeling Projects/Credit Default Prediction Using Logistic Regression and XGBoost/data/X_train.csv', index=False)\n",
    "X_test.to_csv('C:/Users/abdou/Documents/Data_Science_Projects/AbdoulT_DSPortfolio/Credit Risk Modeling Projects/Credit Default Prediction Using Logistic Regression and XGBoost/data/X_test.csv', index=False)\n",
    "y_train.to_csv('C:/Users/abdou/Documents/Data_Science_Projects/AbdoulT_DSPortfolio/Credit Risk Modeling Projects/Credit Default Prediction Using Logistic Regression and XGBoost/data/y_train.csv', index=False)\n",
    "y_test.to_csv('C:/Users/abdou/Documents/Data_Science_Projects/AbdoulT_DSPortfolio/Credit Risk Modeling Projects/Credit Default Prediction Using Logistic Regression and XGBoost/data/y_test.csv', index=False)\n",
    "\n",
    "# Save the processed data to a new CSV file\n",
    "df.to_csv('C:/Users/abdou/Documents/Data_Science_Projects/AbdoulT_DSPortfolio/Credit Risk Modeling Projects/Credit Default Prediction Using Logistic Regression and XGBoost/data/processed_credit_data.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the processed DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Display the shape of the training and testing sets\n",
    "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}, {y_test.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
