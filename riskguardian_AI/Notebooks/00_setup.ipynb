{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd6abf1c",
   "metadata": {},
   "source": [
    "# üìÅ Project: RiskGuardian AI ‚Äî Real-Time Risk Detection and Compliance Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ef0accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Folder structure created.\n"
     ]
    }
   ],
   "source": [
    "# === 00_setup.py ===\n",
    "# Environment & data pipeline setup for RiskGuardian\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Setup folders in project root\n",
    "Path(\"../data/raw\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"../data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"../models\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"../artifacts\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"../data/logs\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Folder structure created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5625b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: SEC EDGAR 10-K Filing Data (Public Companies)\n",
    "# === Function to Fetch and Save SEC Filing Data ===\n",
    "def fetch_sec_10k_10q_from_index(cik: str, company_name: str, user_agent: str = \"RiskGuardianBot/0.1\"):\n",
    "    BASE_URL = \"https://www.sec.gov/Archives/edgar/full-index/2024/QTR1/company.idx\"\n",
    "    HEADERS = {\"User-Agent\": \"RiskGuardianBot/1.0 (abdoulkarim.toure@gmail.com)\"}\n",
    "\n",
    "    response = requests.get(BASE_URL, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        text = response.text\n",
    "        lines = text.splitlines()[11:] # Skip header lines\n",
    "        matches = [line for line in lines if cik in line and (\"10-K\" in line or \"10-Q\" in line)]\n",
    "\n",
    "        if matches:\n",
    "            line = matches[0]  # Get the first match\n",
    "            parts = line.split()\n",
    "            form_type = parts[1] # e.g., \"10-K\" or \"10-Q\"\n",
    "            path = parts[-1]  # e.g., \"0001018724-24-000001.txt\"\n",
    "            doc_url = f\"https://www.sec.gov/Archives/{path}\"\n",
    "\n",
    "            html_resp = requests.get(doc_url, headers=HEADERS)\n",
    "            if html_resp.status_code == 200:\n",
    "                soup = BeautifulSoup(html_resp.text, \"html.parser\")\n",
    "                filing_text = soup.get_text(separator=\"\\n\")\n",
    "                with open(f\"../data/raw/{company_name}_filing.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(filing_text)\n",
    "                print(f\"‚úÖ {company_name} {form_type} filing saved.\")\n",
    "            else:\n",
    "                print(f\"‚ùå Filing download failed: {html_resp.status_code}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No 10-K or 10-Q found in index for {company_name}.\")\n",
    "            pd.DataFrame([[company_name, cik, \"No 10-K/10-Q found\"]],\n",
    "                         columns=[\"company\", \"cik\", \"status\"]).to_csv(\"../data/logs/skipped_companies.csv\", mode='a', header=not os.path.exists(\"../data/logs/skipped_companies.csv\"), index=False)\n",
    "    else:\n",
    "        print(f\"‚ùå Index download failed: {response.status_code}\")\n",
    "        pd.DataFrame([[company_name, cik, f\"Fetch error {response.status_code}\"]],\n",
    "                     columns=[\"company\", \"cik\", \"status\"]).to_csv(\"../data/logs/skipped_companies.csv\", mode='a', header=not os.path.exists(\"../data/logs/skipped_companies.csv\"), index=False)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1481a8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Apple Inc. filing saved.\n",
      "‚ö†Ô∏è No 10-K or 10-Q found in index for Microsoft.\n",
      "‚úÖ Meta Platforms, filing saved.\n",
      "‚úÖ Amazon COM filing saved.\n",
      "‚úÖ Google Inc. filing saved.\n",
      "‚ö†Ô∏è No 10-K or 10-Q found in index for Rise.\n",
      "‚ö†Ô∏è No 10-K or 10-Q found in index for Tesla.\n",
      "‚úÖ Nvidia CORP filing saved.\n"
     ]
    }
   ],
   "source": [
    "# === Loop over multiple companies ===\n",
    "companies = {\n",
    "    \"Apple\": \"0000320193\",\n",
    "    \"Microsoft\": \"0000789019\",\n",
    "    \"Meta\": \"0001326801\",\n",
    "    \"Amazon\": \"0001018724\",\n",
    "    \"Google\": \"0001652044\",\n",
    "    \"Rise\": \"0001640967\",\n",
    "    \"Tesla\": \"0001318605\",\n",
    "    \"Nvidia\": \"0001045810\"\n",
    "}\n",
    "\n",
    "for name, cik in companies.items():\n",
    "    fetch_sec_10k_10q_from_index(cik, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0397d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned filing text for Apple.\n",
      "‚ö†Ô∏è Skipping Microsoft: No raw filing found.\n",
      "‚úÖ Cleaned filing text for Meta.\n",
      "‚úÖ Cleaned filing text for Amazon.\n",
      "‚úÖ Cleaned filing text for Google.\n",
      "‚ö†Ô∏è Skipping Rise: No raw filing found.\n",
      "‚ö†Ô∏è Skipping Tesla: No raw filing found.\n",
      "‚úÖ Cleaned filing text for Nvidia.\n"
     ]
    }
   ],
   "source": [
    "# === 01_preprocess.py ===\n",
    "# Basic cleaning and prep of fetched filings\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "for company in companies:\n",
    "    path = f\"../data/raw/{company}_filing.txt\"\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "        with open(f\"../data/processed/{company}_filing_clean.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            for line in lines:\n",
    "                f.write(line.strip() + \"\\n\")\n",
    "        print(f\"‚úÖ Cleaned filing text for {company}.\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Skipping {company}: No raw filing found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
